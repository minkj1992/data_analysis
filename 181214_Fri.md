# multiple regression

http://commres.net/wiki/multiple_regression
zero-order:  제어없이 독립변인
first order: partial만보는것
partial corr: 

part: semi-partial(part corr)이라고 명칭한다.


#
무엇부터? 라는 문제
그림 여기쯤 수록

Y 변량과 (전체변량) 세개의 독립변인의 설명변량 (X1 X2 X3 ) 간의 관계에 대한 설명 

따라서 어떤 변수를 어떻게 넣는가의 문제가 중요하게 됨.
Enter method (all at once as if they are not related)
Selection methods
Statistical regression methods
Forward selection: X변인들 (predictors) 중 종속변인인 Y와 상관관계가 가장 높은 변인부터 먼저 투입되어 회귀계산이 수행된다. 먼저 투입된 변인은 (상관관계가 높으므로) 이론적으로 종속변인을 설명하는 중요한 요소로 여겨지게 된다. 또한 다음 변인은 우선 투입된 변인을 고려한 상태로 투입된다.
Backward elimination: 모든 독립변인들이 한꺼번에 투입되어 회귀계산이 시작된다. 이어서 회귀식에 통계학적으로 기여하지 못한다고 판단되는 X변인이 하나씩 제거되면서 회귀계산을 반복적으로 한다.
Step-wise selection: Forward와 같은 방식으로 회귀계산을 하되, 투입된 변인의 설명력을 계산하여 버릴 것인지 취할 것인지를 결정한다.
Sequential regression (hierarchical regression or block-wise) method: 이론적 혹은 연구자의 판단에 따라서 독립변인들을 그룹지어 (블럭화하여) 투입하는 것을 말한다. 각 블럭은 회귀계산에 투입되고, 설명력이 충분치 않을 경우 제거된 후 다음 블럭이 더해질 수 있다. 순서가 먼저인 블럭(변인들)이 설명력을 온전히 갖게 되는 경향이 있으므로 앞의 블럭은 그 효과를(설명력을) 제어(콘트롤)하는 것이라고 할 수 있다. 더하여 설명에 기여하지 못하는 변인들을 계산과 해석에서 제거함으로써 독립 변인들의 설명력을 높이는 효과를 결과한다.
What is the difference between hierarchical and stepwise regressions?
. . . the stepwise procedure defines an a posteriori order based solely on a statistical consideration (the statistical significance of semi-partial correlations) . . . .



#

http://commres.net/wiki/statistical_regression_methods

lm.full <- lm(bwt ~ age + lwt + race.cat + smoke + preterm + ht + ui + ftv.cat, data = lbw): sstotal


lm.null <- lm(bwt ~ 1, data = lbw)
: 독립변인 없이 표시하는 것

drop1(lm.full, test = "F")
drop1(update(lm.full, ~ . -age), test = "F")
: -age해달라


backward elimination 하기위해선 drop1()이라는 명령어가 필요하다.	

``` R
Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)    2837.64     243.63   11.65  < 2e-16 ***
lwt               4.24       1.68    2.53  0.01223 *  
race.catBlack  -475.81     145.58   -3.27  0.00129 ** 
race.catOther  -350.00     112.34   -3.12  0.00213 ** 
smoke          -354.90     103.43   -3.43  0.00074 ***
ht             -585.11     199.61   -2.93  0.00381 ** 
ui             -524.44     134.65   -3.89  0.00014 ***
```
이 테이블로 regression equation을 생성할 수 있다.


# Forward selection

add1(lm.null, scope = ~ age + lwt + race.cat + smoke + preterm + ht + ui + ftv.cat, test = "F")

-> y값만 있는 상황인데(null) 여기에 
add1(update(lm.null, ~ . +ui), scope = ~ age + lwt + race.cat + smoke + preterm + ht + ui + ftv.cat, test = "F")


# factor analysis

http://commres.net/wiki/factor_analysis

이론만 설명
 독립변인이 없는데, 있는 것처럼 생각하고 regression하는 것

다수의 변수들 간의 상호관련성을 소수의 요인(factor)으로 정리하는 방법(많은 변수들을 군집화 시켜준다)


그렇게 영향력있는 녀석들로 add시킨다.


# sequential regression
(hierarchical regression or block-wise)
어떤사람은 (hierarchical regression)이라고 하는데, 이는 독립변인이 깅장히 많아

http://commres.net/wiki/r/multiple_regression

다른 변인들은 제어한체로 regression 결과를 보고 anova test를 하여 , f-test결과가 의미가 있었다 할 정도로 상승하였을지 여부 확인.(sequential)
추가적으로 모든 변인을 1개씩 넣는것보단, block으로 묶어서 같은 군집끼리 한번에 넣어준다.

forward selection이랑은 군집block 개념과 컴퓨터가 알아서 골라준다는 것 이외에는 다른것이 없다.

communality(군집) = 각 가짜 변인들의 coefficient ^2 합
specific variance = error
